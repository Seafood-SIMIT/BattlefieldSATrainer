{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211d11d6-3a3a-4ffa-b6de-c18c776507ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037c51f2-7f78-4160-afc4-9c109b328186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad(ids, pad_id, max_length):\n",
    "    if len(ids) > max_length:\n",
    "        return ids[:max_length]\n",
    "    return ids + [pad_id] * (max_length - len(ids))\n",
    "\n",
    "\n",
    "prompt_prefix = \"\"\n",
    "prompt_without_output = \"<human>:{prompt}\\n<bot>:\"\n",
    "\n",
    "@dataclass\n",
    "class LlamaSFTCollator:\n",
    "    '''\n",
    "    由input处理成samples，也就是最终模型的输入\n",
    "    其中主要处理逻辑在__call__里\n",
    "    '''\n",
    "    tokenizer: None  # 分词\n",
    "    max_seq_length: 1536\n",
    "    def __call__(self, samples):\n",
    "        input_ids_list = []\n",
    "        labels_list = []\n",
    "        max_length = 0\n",
    "        for s in samples:\n",
    "            \"\"\"\n",
    "            sample: {\n",
    "                \"task\" : str,\n",
    "                \"prompt\": [str]\n",
    "                \"output\": [str]\n",
    "                }\n",
    "            \"\"\"\n",
    "            prompt_cnt = min(len(s[\"prompt\"]), len(s[\"output\"]))\n",
    "            # input_ids = self.tokenizer(prompt_prefix).input_ids\n",
    "            input_ids = []\n",
    "            labels_ids = [-100] * len(input_ids)\n",
    "            for i in range(prompt_cnt):\n",
    "                prompt_input_ids = self.tokenizer(prompt_without_output.format_map(\n",
    "                    {\"prompt\": s[\"prompt\"][i].strip()}), add_special_tokens=False).input_ids\n",
    "                output_ids = self.tokenizer(s[\"output\"][i].strip(), add_special_tokens=False).input_ids + [self.tokenizer.eos_token_id]\n",
    "                \n",
    "                input_ids += prompt_input_ids\n",
    "                input_ids += output_ids\n",
    "                \n",
    "                labels_ids += [-100] * (len(prompt_input_ids)) + output_ids\n",
    "            \n",
    "            # input_ids += [self.tokenizer.eos_token_id]\n",
    "            # labels_ids += [self.tokenizer.eos_token_id]\n",
    "            max_length = min(max(len(input_ids), max_length), self.max_seq_length)\n",
    "            input_ids_list.append(input_ids)\n",
    "            labels_list.append(labels_ids)\n",
    "\n",
    "        # PAD\n",
    "        for i in range(len(input_ids_list)):\n",
    "            labels_list[i] = pad(labels_list[i], -100, max_length)\n",
    "            input_ids_list[i] = pad(input_ids_list[i], self.tokenizer.eos_token_id, max_length)\n",
    "        model_inputs = {\n",
    "            'input_ids': torch.tensor(input_ids_list).clone(),\n",
    "            'attention_mask': torch.ones((len(input_ids_list), max_length)).clone(),\n",
    "            \"position_ids\": torch.arange(0, max_length).unsqueeze(0).expand(len(input_ids_list), max_length).clone(),\n",
    "            'labels': torch.tensor(labels_list).clone(),\n",
    "        }\n",
    "        return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68cb4c76-741d-4bb6-8c66-3d7b53089196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class Llama(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, args, model,tokenizer):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(args)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def setup(self, stage) -> None:\n",
    "        \n",
    "        if stage == 'fit':\n",
    "            self.total_steps = get_total_steps(self.trainer, self.hparams)\n",
    "            print('Total steps: {}'.format(self.total_steps))\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return configure_optimizers(self)\n",
    "\n",
    "    def forward(self, **batch):\n",
    "        return self.model(**batch)\n",
    "\n",
    "    def detokenize(self, token_ids):\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(token_ids)\n",
    "        return self.tokenizer.convert_tokens_to_string(tokens)\n",
    "\n",
    "    def comput_metrix(self, logits, labels):\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(logits, dim=-1)\n",
    "            y_pred = y_pred.view(size=(-1,))\n",
    "            y_true = labels.view(size=(-1,)).float()\n",
    "            corr = torch.eq(y_pred, y_true)\n",
    "            acc = torch.sum(corr.float())/labels.shape[0]\n",
    "        return acc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        if self.trainer.global_rank == 0:\n",
    "            global SHOW_DATA\n",
    "            if not SHOW_DATA:\n",
    "                SHOW_DATA = True\n",
    "                print('source: {}'.format(batch['input_ids'][0]))\n",
    "                print('target: {}'.format(batch['labels'][0]))\n",
    "                print('source: {}'.format(self.detokenize(batch['input_ids'][0])))\n",
    "                label_idx = batch['labels'][0] != -100\n",
    "                print('target: {}'.format(self.detokenize(\n",
    "                    batch['labels'][0][label_idx])))\n",
    "                print('mask: {}'.format(batch['attention_mask'][0]))\n",
    "                print('position_ids: {}'.format(batch['position_ids'][0]))\n",
    "        output = self(**batch)\n",
    "        self.log('train/loss', output.loss, sync_dist=True)\n",
    "        return output.loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        output = self(**batch)\n",
    "        self.log('val_loss', output.loss, sync_dist=True)\n",
    "        return output.loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        # generate data\n",
    "        generate_kwargs = {\n",
    "        \t\"do_sample\": True,\n",
    "        \t\"top_p\": 1.0,   \n",
    "        \t\"top_k\": 0,\n",
    "        \t\"max_length\": 256,\n",
    "        \t\"repetition_penalty\": 1.0,\n",
    "        \t\"temperature\": 0.8,\n",
    "        \t\"pad_token_id\": self.tokenizer.eos_token_id,\n",
    "        \t\"eos_token_id\": self.tokenizer.eos_token_id,\n",
    "        }\n",
    "        batch_input_ids = batch['input_ids'].cpu().numpy().tolist()\n",
    "        print('batch_input_ids:\\n', batch_input_ids)\n",
    "        queries = [self.detokenize(input_ids).split('<bot>:')[0].replace('<s>', '')+'<bot>:' for input_ids in batch_input_ids]\n",
    "        print('queries:\\n', queries)\n",
    "        # queries = ['怎样给世界一点爱？', '生命的意义是什么？']\n",
    "        ans = generate(queries=queries,\n",
    "                tokenizer=self.tokenizer,\n",
    "                model=self.model,\n",
    "                device=self.model.device,\n",
    "                **generate_kwargs)\n",
    "        print('ans:\\n', ans)\n",
    "        ## end\n",
    "\n",
    "    def on_load_checkpoint(self, checkpoint) -> None:\n",
    "        if 'global_samples' in checkpoint:\n",
    "            self.consumed_samples = checkpoint['global_samples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3caff038-4438-41cc-8fda-1d8aca484adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_seq_length=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7162577b-2cf5-4658-bff3-7549155e5127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "cache_dir = '/root/autodl-tmp/ziya'\n",
    "model_name = 'IDEA-CCNL/Ziya-LLaMA-13B-v1.1'\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name,cache_dir = cache_dir, use_fast=False)\n",
    "collate_fn = LlamaSFTCollator(\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_length=max_seq_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "280d87d8-18fa-4cb1-bec0-a8adead58bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012116193771362305,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading shards",
       "rate": null,
       "total": 28,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87aff47559247f0bc1223bcafe4244d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011707782745361328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00009-of-00028.bin",
       "rate": null,
       "total": 917528001,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38105e6cfd5490c8e9805952b724db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00009-of-00028.bin:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01702737808227539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00010-of-00028.bin",
       "rate": null,
       "total": 985707823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0d4e84ff504bbb8a7f3e4391d1d131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00010-of-00028.bin:   0%|          | 0.00/986M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014330863952636719,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00011-of-00028.bin",
       "rate": null,
       "total": 917528001,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4a5ea0520b4d78bb0111f07c2866b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00011-of-00028.bin:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012271642684936523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00012-of-00028.bin",
       "rate": null,
       "total": 985707823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69537c5486624470a9e176822f3bd3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00012-of-00028.bin:   0%|          | 0.00/986M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011103153228759766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00013-of-00028.bin",
       "rate": null,
       "total": 917528001,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6c4498aaa0412cb481dd8d4e9e9274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00013-of-00028.bin:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01257777214050293,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00014-of-00028.bin",
       "rate": null,
       "total": 985707823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430a421677e845c1bdf8cb690b42abc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00014-of-00028.bin:   0%|          | 0.00/986M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016239166259765625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00015-of-00028.bin",
       "rate": null,
       "total": 917528001,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb4e698764b49d89863dcadc1475a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00015-of-00028.bin:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014278888702392578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00016-of-00028.bin",
       "rate": null,
       "total": 985707823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c009ea7e00442aad390c2ba5b50b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00016-of-00028.bin:   0%|          | 0.00/986M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013568639755249023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00017-of-00028.bin",
       "rate": null,
       "total": 917528001,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673ccd90e258408794f9be4581dec7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00017-of-00028.bin:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015337467193603516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00018-of-00028.bin",
       "rate": null,
       "total": 985707823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46186bf5ff445dab26aa74c31c60fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00018-of-00028.bin:   0%|          | 0.00/986M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01397252082824707,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00019-of-00028.bin",
       "rate": null,
       "total": 917528001,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703551682be44f56bf1d7758e51b634b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00019-of-00028.bin:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01571488380432129,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00020-of-00028.bin",
       "rate": null,
       "total": 985707823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c4fe6d068a46ecadf0abf7264a96b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00020-of-00028.bin:   0%|          | 0.00/986M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008976459503173828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00021-of-00028.bin",
       "rate": null,
       "total": 917528001,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba71090acb6349ad85bf2500a9c89b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00021-of-00028.bin:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013844966888427734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00022-of-00028.bin",
       "rate": null,
       "total": 985707823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffd08411997437da0d17964b2990113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00022-of-00028.bin:   0%|          | 0.00/986M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015537023544311523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00023-of-00028.bin",
       "rate": null,
       "total": 917528001,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07361d52aac047e3ba2fbf202d8eb0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00023-of-00028.bin:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015876054763793945,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00024-of-00028.bin",
       "rate": null,
       "total": 985707823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21823cb44784f9685f91cf91b09b756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00024-of-00028.bin:   0%|          | 0.00/986M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013907670974731445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00025-of-00028.bin",
       "rate": null,
       "total": 917528001,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c38d941037f4d62b824024762e00bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00025-of-00028.bin:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015267610549926758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00026-of-00028.bin",
       "rate": null,
       "total": 985707823,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2e8c8be3804b8eb0018e85ad230053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00026-of-00028.bin:   0%|          | 0.00/986M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014944076538085938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00027-of-00028.bin",
       "rate": null,
       "total": 917528001,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb8c25d07ba4082be532e9e5207652b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00027-of-00028.bin:   0%|          | 0.00/918M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01460886001586914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)l-00028-of-00028.bin",
       "rate": null,
       "total": 545291867,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed257ae69b284e2ead6efa5f008ed4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00028-of-00028.bin:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0055332183837890625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 28,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3b2554bd4340e5a9e847479117f637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014098405838012695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading (…)neration_config.json",
       "rate": null,
       "total": 137,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a7e849eae0410a8772d427e73c0808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "model = LlamaForCausalLM.from_pretrained(model_name,cache_dir = cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ebb283-3b21-4164-ac28-5b4951d4f8e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fengshen.models.megatron'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfengshen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muniversal_datamodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UniversalDataModule\n\u001b[1;32m      2\u001b[0m data_module \u001b[38;5;241m=\u001b[39m UniversalDataModule(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, args\u001b[38;5;241m=\u001b[39margs, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata load complete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/fengshen/data/universal_datamodule/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muniversal_datamodule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UniversalDataModule\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muniversal_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainingSampler, PretrainingRandomSampler\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUniversalDataModule\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPretrainingSampler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPretrainingRandomSampler\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/fengshen/data/universal_datamodule/universal_datamodule.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, DistributedSampler\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfengshen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmegatron\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mpu\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_consume_samples\u001b[39m(data_model: LightningDataModule) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data_model\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconsumed_samples\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fengshen.models.megatron'"
     ]
    }
   ],
   "source": [
    "from fengshen.data.universal_datamodule import UniversalDataModule\n",
    "data_module = UniversalDataModule(tokenizer=tokenizer, args=args, collate_fn=collate_fn)\n",
    "print('data load complete')\n",
    "model = Llama(args,model, tokenizer=tokenizer)\n",
    "print('model load complete')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "998ce8d4-9d77-42b9-b031-66d4c695ad90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "import fengshen\n",
    "print(dir(fengshen.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa985e48-829a-4edf-8519-2c2cb612ce4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
